{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "\n",
    "# ====== DEERS: Model Definition ====== #\n",
    "class DeepAutoencoderThreeHiddenLayers(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, code_dim, activation_func=nn.ReLU,\n",
    "                 code_activation=True, dropout=False, dropout_rate=0.5):\n",
    "        super(DeepAutoencoderThreeHiddenLayers, self).__init__()\n",
    "        # Establish encoder\n",
    "        modules = []\n",
    "        modules.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        modules.append(activation_func())\n",
    "        if dropout:\n",
    "            modules.append(nn.Dropout(dropout_rate))\n",
    "            \n",
    "        for input_size, output_size in zip(hidden_dims, hidden_dims[1:]):\n",
    "            modules.append(nn.Linear(input_size, output_size))\n",
    "            modules.append(activation_func())\n",
    "            if dropout:\n",
    "                modules.append(nn.Dropout(dropout_rate))\n",
    "                \n",
    "        modules.append(nn.Linear(hidden_dims[-1], code_dim))\n",
    "        if code_activation:\n",
    "            modules.append(activation_func())\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        \n",
    "        # Establish decoder\n",
    "        modules = []\n",
    "        \n",
    "        modules.append(nn.Linear(code_dim, hidden_dims[-1]))\n",
    "        modules.append(activation_func())\n",
    "        if dropout:\n",
    "            modules.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        for input_size, output_size in zip(hidden_dims[::-1], hidden_dims[-2::-1]):\n",
    "            modules.append(nn.Linear(input_size, output_size))\n",
    "            modules.append(activation_func())\n",
    "            if dropout:\n",
    "                modules.append(nn.Dropout(dropout_rate))\n",
    "        modules.append(nn.Linear(hidden_dims[0], input_dim))\n",
    "        modules.append(nn.Sigmoid())\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        code = x\n",
    "        x = self.decoder(x)\n",
    "        return code, x\n",
    "    \n",
    "\n",
    "class ForwardNetworkTwoHiddenLayers(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, activation_func=nn.ReLU,\n",
    "                out_activation=None):\n",
    "        super(ForwardNetworkTwoHiddenLayers, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "             nn.Linear(input_dim, hidden_dim1),\n",
    "             nn.BatchNorm1d(hidden_dim1),\n",
    "             activation_func(),\n",
    "             nn.Linear(hidden_dim1, hidden_dim2),\n",
    "             nn.BatchNorm1d(hidden_dim2),\n",
    "             activation_func(),\n",
    "             nn.Linear(hidden_dim2, 1))\n",
    "        \n",
    "        self.out_activation = out_activation\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.out_activation:\n",
    "            return self.out_activation(self.layers(x))\n",
    "        else:\n",
    "            return self.layers(x)\n",
    "\n",
    "class DEERS_Concat(torch.nn.Module):\n",
    "    def __init__(self, drug_autoencoder, mut_line_autoencoder,\n",
    "                 forward_network):\n",
    "        super(DEERS_Concat, self).__init__()\n",
    "        self.drug_autoencoder = drug_autoencoder\n",
    "        self.mut_line_autoencoder = mut_line_autoencoder\n",
    "        self.forward_network = forward_network\n",
    "        \n",
    "    def forward(self, drug_features, mut_features, cell_features):\n",
    "        \n",
    "        drug_code, drug_reconstruction = self.drug_autoencoder(drug_features)\n",
    "        mut_code, mut_reconstruction = self.mut_line_autoencoder(mut_features)\n",
    "        x = torch.cat((drug_code, mut_code, cell_features), axis=1)    ####\n",
    "        return self.forward_network(x), drug_reconstruction, mut_reconstruction\n",
    "    \n",
    "class MergedLoss(nn.Module):\n",
    "    def __init__(self, y_loss_weight=1., drug_reconstruction_loss_weight=0.1, mut_reconstruction_loss_weight=0.2):\n",
    "        super(MergedLoss, self).__init__()\n",
    "        self.y_loss_weight = y_loss_weight\n",
    "        self.drug_reconstruction_loss_weight = drug_reconstruction_loss_weight\n",
    "        self.mut_reconstruction_loss_weight = mut_reconstruction_loss_weight\n",
    "        self.output_criterion = nn.MSELoss()\n",
    "        self.reconstruction_criterion = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, pred_y, drug_reconstruction, mut_reconstruction,drug_input,mut_input, true_y):\n",
    "        output_loss = self.output_criterion(pred_y, true_y)\n",
    "        drug_reconstruction_loss = self.reconstruction_criterion(drug_reconstruction, drug_input)\n",
    "        mut_reconstruction_loss = self.reconstruction_criterion(mut_reconstruction, mut_input)\n",
    "        return output_loss, drug_reconstruction_loss,mut_reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dr = pd.read_csv(\"E:\\Bioinfomation Data\\Drug Response\\GDSC\\Data\\model_input\\GDSC\\GDSC_SMILE_input.csv\", sep=',', header=0)\n",
    "mut_score_df = pd.read_csv(\"E:\\Bioinfomation Data\\Drug Response\\GDSC\\Data\\model_input\\GDSC\\GDSC_mutation_input.csv\", sep=',', header=0)\n",
    "cell_exprs_df = pd.read_csv(\"E:\\Bioinfomation Data\\Drug Response\\GDSC\\Data\\model_input\\GDSC\\GDSC_ssgsea_input.csv\", sep=',', header=0)\n",
    "samples_train = pd.read_csv(\"E:\\Bioinfomation Data\\Drug Response\\GDSC\\Data\\model_input\\GDSC\\GDSC_IC50_by_both.csv\", sep=',', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load(\"E:/Bioinfomation Data/Drug Response/GDSC/Results/my_both/IC50_CV00/my_both__cv00.model\")\n",
    "drug_autoencoder=model.drug_autoencoder\n",
    "mut_autoencoder=model.mut_line_autoencoder\n",
    "\n",
    "drug_mut_exp_attributions_list = []\n",
    "for i in range(1,int(samples_train.copy().shape[0]/50)):\n",
    "    samples = samples_train.copy()[(i-1)*50:i*50]\n",
    "\n",
    "    cell_idx = samples['cell_idx']\n",
    "    drug_idx = samples['drug_idx']\n",
    "\n",
    "    drug_input = torch.from_numpy(dr.loc[drug_idx.values].iloc[:, 2:].values.astype('float64')).float()\n",
    "    cl_input1 = torch.from_numpy(mut_score_df.loc[cell_idx.values].iloc[:, 2:].values.astype('float64')).float()\n",
    "    cl_input2 = torch.from_numpy(cell_exprs_df.loc[cell_idx.values].iloc[:, 2:].values.astype('float64')).float()\n",
    "    mut_codes, mut_recs = mut_autoencoder(cl_input1)\n",
    "\n",
    "    dr_codes, dr_recs = drug_autoencoder(drug_input)\n",
    "\n",
    "    forward_input = torch.cat((dr_codes, mut_codes, cl_input2),axis = 1)\n",
    "\n",
    "    def net(forward_input):\n",
    "        return model.forward_network(forward_input)\n",
    "    ig = IntegratedGradients(net)\n",
    "\n",
    "    forward_input.requires_grad_()\n",
    "    forward_input.shape\n",
    "\n",
    "    attributions, delta = ig.attribute(forward_input, return_convergence_delta=True)\n",
    "    drug_mut_exp_attributions = attributions\n",
    "    drug_mut_exp_attributions = drug_mut_exp_attributions.cpu().detach().numpy()\n",
    "    drug_mut_exp_attributions = np.mean(drug_mut_exp_attributions, axis=0)\n",
    "    drug_mut_exp_attributions_list.append(drug_mut_exp_attributions)\n",
    "\n",
    "print(drug_mut_exp_attributions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(drug_mut_exp_attributions_list))\n",
    "drug = np.array(drug_mut_exp_attributions_list)\n",
    "drug_mut_exp_attributions = np.mean(drug, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(drug_mut_exp_attributions[1:])\n",
    "csv_file_path = 'E:\\Bioinfomation Data\\Drug Response\\GDSC\\Data\\model_input\\GDSC\\drug_mut_exp_attributions.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepDrug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
